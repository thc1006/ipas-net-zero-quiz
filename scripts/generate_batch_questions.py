#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾ MISSING_ANSWERS_ANALYSIS.json ç”ŸæˆæŒ‡å®š Batch çš„é¡Œç›®æ¸…å–®
ç”¨æ–¼ä¸¦è¡Œé©—è­‰å·¥ä½œ
"""

import json
import sys
from pathlib import Path

# Windows ç·¨ç¢¼ä¿®æ­£
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

def load_json(file_path: Path):
    """è¼‰å…¥ JSON æª”æ¡ˆ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_json(data, file_path: Path):
    """å„²å­˜ JSON æª”æ¡ˆ"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def generate_batch_questions(batch_name: str, start_idx: int, batch_size: int):
    """
    ç”ŸæˆæŒ‡å®š Batch çš„é¡Œç›®æ¸…å–®

    Args:
        batch_name: Batch åç¨± (A, B, C, D, E, F)
        start_idx: èµ·å§‹ç´¢å¼•ï¼ˆå¾å„ªå…ˆç´šæ¸…å–®ä¸­ï¼‰
        batch_size: Batch å¤§å°
    """
    base_dir = Path(__file__).parent.parent

    # è¼‰å…¥åˆ†æå ±å‘Š
    analysis_file = base_dir / 'MISSING_ANSWERS_ANALYSIS.json'
    if not analysis_file.exists():
        print(f"âŒ æ‰¾ä¸åˆ°åˆ†æå ±å‘Š: {analysis_file}")
        return None

    analysis = load_json(analysis_file)
    prioritized = analysis['prioritized']

    # æå–æŒ‡å®šç¯„åœçš„é¡Œç›®
    batch_questions = prioritized[start_idx:start_idx + batch_size]

    # å¾ integrated_dataset.json æå–å®Œæ•´é¡Œç›®è³‡è¨Š
    dataset_file = base_dir / 'quiz-app' / 'src' / 'data' / 'integrated_dataset.json'
    dataset = load_json(dataset_file)

    # å»ºç«‹ç´¢å¼•æ˜ å°„
    full_questions = []
    for item in dataset.get('gist_items', []):
        idx = item.get('index')
        if any(q['index'] == idx for q in batch_questions):
            full_questions.append({
                'index': idx,
                'number': item.get('number'),
                'subject': item.get('exam_subject'),
                'question': item.get('stem'),
                'options': item.get('options', {}),
                'answer': None,  # éœ€è¦é©—è­‰
                'source': 'gist',
                'priority_score': next(q['priority_score'] for q in batch_questions if q['index'] == idx),
                'keywords': next(q['keywords'] for q in batch_questions if q['index'] == idx)
            })

    for item in dataset.get('our_unique_items', []):
        idx = item.get('index')
        if any(q['index'] == idx for q in batch_questions):
            full_questions.append({
                'index': idx,
                'number': item.get('number'),
                'subject': item.get('exam_subject'),
                'question': item.get('stem'),
                'options': item.get('options', {}),
                'answer': None,
                'source': 'our_unique',
                'priority_score': next(q['priority_score'] for q in batch_questions if q['index'] == idx),
                'keywords': next(q['keywords'] for q in batch_questions if q['index'] == idx)
            })

    # æŒ‰å„ªå…ˆç´šæ’åº
    full_questions.sort(key=lambda x: x['priority_score'], reverse=True)

    # ç”Ÿæˆè¼¸å‡º
    output = {
        'batch_name': batch_name,
        'batch_size': len(full_questions),
        'priority_range': f"{start_idx + 1} ~ {start_idx + len(full_questions)}",
        'questions': full_questions,
        'summary': {
            'total': len(full_questions),
            'by_subject': {},
            'by_keywords': {}
        }
    }

    # çµ±è¨ˆ
    from collections import Counter
    subject_counter = Counter(q['subject'] for q in full_questions)
    all_keywords = []
    for q in full_questions:
        all_keywords.extend(q['keywords'])
    keyword_counter = Counter(all_keywords)

    output['summary']['by_subject'] = dict(subject_counter)
    output['summary']['by_keywords'] = dict(keyword_counter.most_common(10))

    return output

def main():
    import argparse
    parser = argparse.ArgumentParser(description='ç”Ÿæˆ 266 é¡Œçš„ Batch é¡Œç›®æ¸…å–®')
    parser.add_argument('batch', choices=['A', 'B', 'C', 'D', 'E', 'F'],
                       help='Batch åç¨±')
    parser.add_argument('--size', type=int, default=45,
                       help='Batch å¤§å°ï¼ˆé è¨­ 45ï¼‰')

    args = parser.parse_args()

    # Batch èµ·å§‹ç´¢å¼•æ˜ å°„
    batch_starts = {
        'A': 0,    # 0-44
        'B': 45,   # 45-89
        'C': 90,   # 90-134
        'D': 135,  # 135-179
        'E': 180,  # 180-224
        'F': 225   # 225-265 (41é¡Œ)
    }

    batch_name = args.batch
    start_idx = batch_starts[batch_name]

    # æ ¹æ“šå¯¦éš› prioritized æ¸…å–®é•·åº¦èª¿æ•´ batch_size
    analysis_file = Path(__file__).parent.parent / 'MISSING_ANSWERS_ANALYSIS.json'
    analysis = load_json(analysis_file)
    total_prioritized = len(analysis['prioritized'])

    # è¨ˆç®—å¯¦éš›å¯ç”¨é¡Œæ•¸
    remaining = total_prioritized - start_idx
    batch_size = min(args.size, remaining)

    if batch_name == 'F':
        batch_size = remaining  # F å–å‰©é¤˜æ‰€æœ‰é¡Œç›®

    print("="*60)
    print(f"ğŸ“‹ ç”Ÿæˆ 266 é¡Œ Batch {batch_name} é¡Œç›®æ¸…å–®")
    print("="*60)

    output = generate_batch_questions(batch_name, start_idx, batch_size)

    if output:
        # å„²å­˜æª”æ¡ˆ
        base_dir = Path(__file__).parent.parent
        output_file = base_dir / f'266_batch_{batch_name.lower()}_questions.json'
        save_json(output, output_file)

        print(f"\nâœ… Batch {batch_name} é¡Œç›®æ¸…å–®å·²ç”Ÿæˆ")
        print(f"ğŸ“ æª”æ¡ˆ: {output_file}")
        print(f"\nğŸ“Š çµ±è¨ˆ:")
        print(f"  ç¸½é¡Œæ•¸: {output['summary']['total']}")
        print(f"  å„ªå…ˆç´šç¯„åœ: {output['priority_range']}")
        print(f"\n  æŒ‰è€ƒç§‘:")
        for subject, count in output['summary']['by_subject'].items():
            print(f"    {subject}: {count} é¡Œ")
        print(f"\n  é—œéµå­— (å‰ 5):")
        for keyword, count in list(output['summary']['by_keywords'].items())[:5]:
            print(f"    {keyword}: {count} é¡Œ")
        print("="*60)
    else:
        print("âŒ ç”Ÿæˆå¤±æ•—")
        sys.exit(1)

if __name__ == '__main__':
    main()
