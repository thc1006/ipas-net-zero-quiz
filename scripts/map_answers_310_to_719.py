#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°‡ 310 é¡Œçš„é©—è­‰ç­”æ¡ˆæ˜ å°„åˆ° 719 é¡Œè³‡æ–™é›†
åŸºæ–¼ DATASET_ANALYSIS_REPORT.json çš„å°æ‡‰é—œä¿‚
"""

import json
import sys
from pathlib import Path
from datetime import datetime

# Windows ç·¨ç¢¼ä¿®æ­£
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

def load_json(file_path: Path):
    """è¼‰å…¥ JSON æª”æ¡ˆ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_json(data, file_path: Path):
    """å„²å­˜ JSON æª”æ¡ˆ"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def map_answers(q310_data, q719_data, analysis_report):
    """å°‡ 310 é¡Œç­”æ¡ˆæ˜ å°„åˆ° 719 é¡Œ"""

    matches = analysis_report['matches']['text_match']

    print(f"ğŸ“ é–‹å§‹æ˜ å°„ {len(matches)} çµ„ç­”æ¡ˆ...")

    # å»ºç«‹ 310 é¡Œçš„ç­”æ¡ˆç´¢å¼•
    q310_answers = {item['id']: item for item in q310_data}

    # çµ±è¨ˆ
    stats = {
        'total_matches': len(matches),
        'updated': 0,
        'conflicts': 0,
        'already_correct': 0
    }

    updates = []

    # è™•ç† gist_items
    for item in q719_data.get('gist_items', []):
        idx = item.get('index')

        # å°‹æ‰¾å°æ‡‰çš„åŒ¹é…
        match = next((m for m in matches if m['q719_index'] == idx), None)

        if match:
            q310_id = match['q310_id']
            q310_item = q310_answers.get(q310_id)

            if q310_item:
                old_answer = item.get('answer')
                new_answer = q310_item['answer']

                if old_answer != new_answer:
                    item['answer'] = new_answer

                    # å¦‚æœ 310 é¡Œæœ‰ explanationï¼Œä¹Ÿæ›´æ–°
                    if 'explanation' in q310_item and q310_item['explanation']:
                        item['explanation'] = q310_item['explanation']

                    updates.append({
                        'q719_index': idx,
                        'q310_id': q310_id,
                        'old_answer': old_answer,
                        'new_answer': new_answer,
                        'status': 'updated'
                    })

                    if old_answer is not None:
                        stats['conflicts'] += 1
                    else:
                        stats['updated'] += 1
                else:
                    stats['already_correct'] += 1

    # è™•ç† our_unique_items
    for item in q719_data.get('our_unique_items', []):
        idx = item.get('index')

        match = next((m for m in matches if m['q719_index'] == idx), None)

        if match:
            q310_id = match['q310_id']
            q310_item = q310_answers.get(q310_id)

            if q310_item:
                old_answer = item.get('answer')
                new_answer = q310_item['answer']

                if old_answer != new_answer:
                    item['answer'] = new_answer

                    if 'explanation' in q310_item and q310_item['explanation']:
                        item['explanation'] = q310_item['explanation']

                    updates.append({
                        'q719_index': idx,
                        'q310_id': q310_id,
                        'old_answer': old_answer,
                        'new_answer': new_answer,
                        'status': 'updated'
                    })

                    if old_answer is not None:
                        stats['conflicts'] += 1
                    else:
                        stats['updated'] += 1
                else:
                    stats['already_correct'] += 1

    return q719_data, stats, updates

def main():
    base_dir = Path(__file__).parent.parent

    print("="*60)
    print("ğŸ”„ 310 é¡Œç­”æ¡ˆæ˜ å°„åˆ° 719 é¡Œ")
    print("="*60)

    # è¼‰å…¥è³‡æ–™
    print("\nğŸ“¥ è¼‰å…¥è³‡æ–™...")
    q310_data = load_json(base_dir / 'quiz-app' / 'src' / 'data' / 'questions.json')
    q719_data = load_json(base_dir / 'quiz-app' / 'src' / 'data' / 'integrated_dataset.json')
    analysis_report = load_json(base_dir / 'DATASET_ANALYSIS_REPORT.json')

    print(f"âœ… 310 é¡Œè³‡æ–™: {len(q310_data)} é¡Œ")
    print(f"âœ… 719 é¡Œè³‡æ–™: {analysis_report['summary']['q719_total']} é¡Œ")

    # åŸ·è¡Œæ˜ å°„
    print("\nğŸ”„ åŸ·è¡Œç­”æ¡ˆæ˜ å°„...")
    updated_719, stats, updates = map_answers(q310_data, q719_data, analysis_report)

    # å„²å­˜æ›´æ–°å¾Œçš„ 719 é¡Œè³‡æ–™é›†
    output_file = base_dir / 'quiz-app' / 'src' / 'data' / 'integrated_dataset_updated.json'
    save_json(updated_719, output_file)

    # å„²å­˜æ›´æ–°æ—¥èªŒ
    update_log = {
        'timestamp': datetime.now().isoformat(),
        'stats': stats,
        'updates': updates
    }
    log_file = base_dir / 'ANSWER_MAPPING_LOG.json'
    save_json(update_log, log_file)

    # è¼¸å‡ºçµ±è¨ˆ
    print("\n" + "="*60)
    print("ğŸ“Š æ˜ å°„çµ±è¨ˆ")
    print("="*60)
    print(f"ç¸½åŒ¹é…æ•¸: {stats['total_matches']}")
    print(f"âœ… æ–°å¢ç­”æ¡ˆ: {stats['updated']}")
    print(f"âš ï¸  ç­”æ¡ˆè¡çªï¼ˆå·²è¦†è“‹ï¼‰: {stats['conflicts']}")
    print(f"âœ“  ç­”æ¡ˆå·²æ­£ç¢º: {stats['already_correct']}")
    print(f"\nğŸ“ æ›´æ–°æª”æ¡ˆ: {output_file}")
    print(f"ğŸ“ æ›´æ–°æ—¥èªŒ: {log_file}")
    print("="*60)

    # è¨ˆç®—å‰©é¤˜ç„¡ç­”æ¡ˆé¡Œæ•¸
    remaining_no_answer = analysis_report['summary']['unmatched_no_answer']
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥: é‚„æœ‰ {remaining_no_answer} é¡Œéœ€è¦æ‰¾ç­”æ¡ˆ")

if __name__ == '__main__':
    main()
